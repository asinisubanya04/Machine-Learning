{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cee3c6a5-b89b-4304-8611-bea778390902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, left=None, right=None, feature=None, threshold=None, value=None, leaf=True):\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.value = value #either a split condition (feature or value) or leaf node \n",
    "        self.leaf = leaf\n",
    "        \n",
    "\n",
    "    def get_n_min(n_min, y):\n",
    "        return max(1, int((n_min / 100) * len(y)))\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, root=None):\n",
    "        self.root = root #initalizes the root\n",
    "        self.n_min = None\n",
    "        \n",
    "    def get_n_min(self, n_min, y):\n",
    "        return max(1, int((n_min / 100) * len(y)))\n",
    "        \n",
    "    def entropy(self, y):\n",
    "        entropy = 0\n",
    "        size = len(y)\n",
    "        unique_values, counts = np.unique(y, return_counts=True)\n",
    "        for i in range(len(unique_values)):\n",
    "            p_i = counts[i]/size\n",
    "            if (p_i <= 0):  \n",
    "                continue\n",
    "            entropy -= p_i * np.log2(p_i)\n",
    "        return entropy\n",
    "    \n",
    "    def information_gain(self, split_feature, split_threshold, y): #threshold: value at which dataset is split\n",
    "        size = len(y)\n",
    "        curr_entropy = self.entropy(y)\n",
    "        left_indices = np.nonzero(split_feature <= split_threshold)[0]\n",
    "        right_indices = np.nonzero(split_feature > split_threshold)[0]\n",
    "        if len(left_indices) == 0 or len(right_indices) == 0: #if empty group, return current value, no more splits\n",
    "            return 0\n",
    "        new = ((len(y[left_indices])/size) * self.entropy(y[left_indices])) + ((len(y[right_indices])/size)*self.entropy(y[right_indices]))\n",
    "        return curr_entropy - new  \n",
    "    \n",
    "    def most_occuring_label(self, y): #assigning the most frequent label to leaf Nodes to give its final value/class after all splits\n",
    "        unique_values, counts = np.unique(y, return_counts=True)\n",
    "        max_index = np.argmax(counts)\n",
    "        return unique_values[max_index]\n",
    "    \n",
    "    def choose_best_split(self, X, y): #loop through all features to find best root and nodes w highest ig\n",
    "        best_gain = -1\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "        for i in range(X.shape[1]):\n",
    "            unique_values = np.unique(X[:,i])\n",
    "            if len(unique_values)==1: #1 unique value of feature  \n",
    "                continue\n",
    "            for values in unique_values:\n",
    "                ig = self.information_gain(X[:,i], values, y)  \n",
    "                if (ig>best_gain):\n",
    "                    best_gain = ig\n",
    "                    best_feature = i\n",
    "                    best_threshold = values\n",
    "        return best_feature, best_threshold\n",
    "    \n",
    "    def create_tree(self, X, y, n_min, depth=0):\n",
    "        minimum = self.get_n_min(n_min, y)  \n",
    "        if (len(np.unique(y))==1) or (X.shape[0] < minimum):\n",
    "            return Node(value=self.most_occuring_label(y), leaf=True)  \n",
    "        best_feature, best_threshold = self.choose_best_split(X, y)\n",
    "        if best_feature is None: \n",
    "            return Node(value=self.most_occuring_label(y), leaf=True)  \n",
    "        \n",
    "        left_indices = np.nonzero(X[:, best_feature] <= best_threshold)[0]  \n",
    "        right_indices = np.nonzero(X[:, best_feature] > best_threshold)[0] \n",
    "        X_left = X[left_indices,:]\n",
    "        X_right = X[right_indices,:]\n",
    "        y_left = y[left_indices]  \n",
    "        y_right = y[right_indices]  \n",
    "        \n",
    "        left_subtree = self.create_tree(X_left, y_left, n_min)\n",
    "        right_subtree = self.create_tree(X_right, y_right, n_min)\n",
    "        \n",
    "        return Node(left=left_subtree, right=right_subtree, feature=best_feature, \n",
    "                   threshold=best_threshold, leaf=False)  \n",
    "    \n",
    "    def fit(self, X, y, n_min): #training, actually builds the tree \n",
    "        self.n_min = n_min\n",
    "        self.root = self.create_tree(X, y, self.n_min)\n",
    "    \n",
    "    def predict_one(self, node, sample): \n",
    "        if node.leaf: #if node leaf\n",
    "            return node.value \n",
    "        elif sample[node.feature] <= node.threshold:\n",
    "            return self.predict_one(node.left, sample)  \n",
    "        elif sample[node.feature] > node.threshold:\n",
    "            return self.predict_one(node.right, sample)  \n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_predictions = [] #initialliy empty\n",
    "        for i in range(X.shape[0]):\n",
    "            y_predictions.append(self.predict_one(self.root, X[i]))\n",
    "        return np.array(y_predictions)  #  for easier comparison\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9a2a14-215f-4f08-8f6c-fc6b7c13cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(X, y, n_min=None):\n",
    "    if n_min is None:\n",
    "        n_min = [5]\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    n_min_all = {}\n",
    "    \n",
    "    for i in n_min:\n",
    "        train_accuracies = []\n",
    "        test_accuracies = []\n",
    "        \n",
    "        for train_index, test_index in kf.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]  \n",
    "            y_train, y_test = y[train_index], y[test_index]  \n",
    "            \n",
    "            tree_train = DecisionTree()\n",
    "            tree_train.fit(X_train, y_train, i)  \n",
    "            \n",
    "            train_preds = tree_train.predict(X_train)  \n",
    "            train_accuracy = np.mean(train_preds == y_train)\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            \n",
    "            test_preds = tree_train.predict(X_test)  \n",
    "            test_accuracy = np.mean(test_preds == y_test)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "        \n",
    "        # mean and standard deviation of accuracies for training and testing\n",
    "        mean_train_accuracy = np.mean(train_accuracies)\n",
    "        std_train_accuracy = np.std(train_accuracies)\n",
    "        mean_test_accuracy = np.mean(test_accuracies)\n",
    "        std_test_accuracy = np.std(test_accuracies)\n",
    "        \n",
    "        # results for the current n_min value\n",
    "        n_min_all[i] = {  \n",
    "            'mean_train_accuracy': mean_train_accuracy,\n",
    "            'std_train_accuracy': std_train_accuracy,\n",
    "            'mean_test_accuracy': mean_test_accuracy,\n",
    "            'std_test_accuracy': std_test_accuracy\n",
    "        }\n",
    "    \n",
    "    return n_min_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b23bec-9fd4-4541-bfc9-99e2eb025ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = pd.read_csv(\"iris.csv\", names=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"class\"])\n",
    "with pd.option_context('future.no_silent_downcasting', True):\n",
    "    iris_df= iris_df.replace({'Iris-setosa':0, 'Iris-versicolor': 1, 'Iris-virginica': 2}).infer_objects()\n",
    "    iris = iris_df.to_numpy()\n",
    "    iris_x = iris[:,:-1]\n",
    "    iris_y = iris[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7081dd02-c186-41e2-904e-1a19f2a0257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: {'mean_train_accuracy': 1.0, 'std_train_accuracy': 0.0, 'mean_test_accuracy': 0.9466666666666667, 'std_test_accuracy': 0.0581186525805423}, 10: {'mean_train_accuracy': 1.0, 'std_train_accuracy': 0.0, 'mean_test_accuracy': 0.9466666666666667, 'std_test_accuracy': 0.0581186525805423}, 15: {'mean_train_accuracy': 1.0, 'std_train_accuracy': 0.0, 'mean_test_accuracy': 0.9466666666666667, 'std_test_accuracy': 0.0581186525805423}, 20: {'mean_train_accuracy': 1.0, 'std_train_accuracy': 0.0, 'mean_test_accuracy': 0.9466666666666667, 'std_test_accuracy': 0.0581186525805423}}\n"
     ]
    }
   ],
   "source": [
    "print(cross_validate(iris_x, iris_y, n_min =[5,10,15,20]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1017a76-d563-4039-b9d5-d9f2451ee172",
   "metadata": {},
   "outputs": [],
   "source": [
    "spambase_df = pd.read_csv(\"spambase.csv\")\n",
    "spambase = spambase_df.to_numpy()\n",
    "spambase_y = spambase[:,-1]\n",
    "spambase_x = spambase[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e2b7cd-0c07-459e-bf3c-088a94e16e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{5: {'mean_train_accuracy': 0.9993961352657005, 'std_train_accuracy': 0.00019474052532119157, 'mean_test_accuracy': 0.9178260869565218, 'std_test_accuracy': 0.014737783701459383}, 10: {'mean_train_accuracy': 0.9993961352657005, 'std_train_accuracy': 0.00019474052532119157, 'mean_test_accuracy': 0.9178260869565218, 'std_test_accuracy': 0.014737783701459383}, 15: {'mean_train_accuracy': 0.9993961352657005, 'std_train_accuracy': 0.00019474052532119157, 'mean_test_accuracy': 0.9178260869565218, 'std_test_accuracy': 0.014737783701459383}, 20: {'mean_train_accuracy': 0.9993961352657005, 'std_train_accuracy': 0.00019474052532119157, 'mean_test_accuracy': 0.9178260869565218, 'std_test_accuracy': 0.014737783701459383}, 25: {'mean_train_accuracy': 0.9993961352657005, 'std_train_accuracy': 0.00019474052532119157, 'mean_test_accuracy': 0.9178260869565218, 'std_test_accuracy': 0.014737783701459383}}\n"
     ]
    }
   ],
   "source": [
    "print(cross_validate(spambase_x,spambase_y,n_min=[5,10,15,20,25]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867ea2c4-6212-4d61-9f6e-7a74b1518056",
   "metadata": {},
   "source": [
    "\n",
    "A tree structure is implemented in this model. For this, a Node class is created to represent each node in the decision tree, with attributes for internal nodes, split conidtions, and values. The best splits are determined with the use of calculations of entropy and information gain. Instead of growing a full tree, minimum number of instances (n_min), approach is used where nodes are only split further if they contain more than a certain percentage of the training data. The model is evaluated using 10 fold cross validation across different n_min values 5% to 20% for iris dataset & 5-25% for spambase dataset.\n",
    "To measure the performance of the model, mean training and testing accuracy along with standard deviations are recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8933bc18-6fc2-48a8-9c1e-ab48d300e9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
