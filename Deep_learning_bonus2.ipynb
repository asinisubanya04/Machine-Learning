{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58494076-97fd-45e3-ac65-d864efe0f716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import gzip\n",
    "import urllib.request\n",
    "import os\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1def17ae-f1a8-4ad0-8f26-409dcc05f24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST dataset downloaded.\n",
      "Train images shape: (60000, 28, 28, 1)\n",
      "Test images shape: (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# MNIST Data Loader (using Google Cloud Storage)\n",
    "# -------------------------\n",
    "def download_mnist(path='mnist'):\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    base_url = \"https://storage.googleapis.com/cvdf-datasets/mnist/\"\n",
    "    files = {\n",
    "        \"train_images\": \"train-images-idx3-ubyte.gz\",\n",
    "        \"train_labels\": \"train-labels-idx1-ubyte.gz\",\n",
    "        \"test_images\": \"t10k-images-idx3-ubyte.gz\",\n",
    "        \"test_labels\": \"t10k-labels-idx1-ubyte.gz\"\n",
    "    }\n",
    "    for key, filename in files.items():\n",
    "        filepath = os.path.join(path, filename)\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            urllib.request.urlretrieve(base_url + filename, filepath)\n",
    "    print(\"MNIST dataset downloaded.\")\n",
    "\n",
    "def load_mnist_images(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
    "        images = images.astype(np.float32) / 255.0  # Normalize to [0,1]\n",
    "        return images\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
    "        return labels\n",
    "\n",
    "def load_mnist(path='mnist'):\n",
    "    download_mnist(path)\n",
    "    train_images = load_mnist_images(os.path.join(path, \"train-images-idx3-ubyte.gz\"))\n",
    "    train_labels = load_mnist_labels(os.path.join(path, \"train-labels-idx1-ubyte.gz\"))\n",
    "    test_images = load_mnist_images(os.path.join(path, \"t10k-images-idx3-ubyte.gz\"))\n",
    "    test_labels = load_mnist_labels(os.path.join(path, \"t10k-labels-idx1-ubyte.gz\"))\n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Load MNIST training images\n",
    "train_images, train_labels, test_images, test_labels = load_mnist()\n",
    "# Reshape images to (num_samples, height, width, channels)\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "print(f\"Train images shape: {train_images.shape}\")\n",
    "print(f\"Test images shape: {test_images.shape}\")\n",
    "\n",
    "\n",
    "# --- Helper for weight initialization ---\n",
    "def he_initialize_weights(input_dim, output_dim):\n",
    "    return np.random.randn(input_dim, output_dim) * np.sqrt(2.0 / input_dim)\n",
    "\n",
    "def he_initialize_conv_filters(filter_height, filter_width, input_channels, output_channels):\n",
    "    return np.random.randn(filter_height, filter_width, input_channels, output_channels) * \\\n",
    "           np.sqrt(2.0 / (filter_height * filter_width * input_channels))\n",
    "\n",
    "def xavier_initialize_weights(input_dim, output_dim):\n",
    "    return np.random.randn(input_dim, output_dim) * np.sqrt(1.0 / input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04326084-c1a4-4fbe-abf3-0c8690d89a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.output = 1 / (1 + np.exp(-np.clip(x, -700, 700))) # Clip for numerical stability\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * self.output * (1 - self.output)\n",
    "\n",
    "    def get_params(self): return []\n",
    "    def get_grads(self): return []\n",
    "    def zero_grads(self): pass\n",
    "\n",
    "\n",
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dinput = dout.copy()\n",
    "        if self.input is not None: # Ensure input was set\n",
    "          dinput[self.input <= 0] = 0\n",
    "        return dinput\n",
    "\n",
    "    def get_params(self): return []\n",
    "    def get_grads(self): return []\n",
    "    def zero_grads(self): pass\n",
    "        \n",
    "\n",
    "class LeakyReLU:\n",
    "    def __init__(self, alpha=0.01):\n",
    "        self.alpha = alpha\n",
    "        self.input = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.where(x > 0, x, self.alpha * x)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dinput = dout.copy()\n",
    "        if self.input is not None: # Ensure input was set\n",
    "            dinput[self.input <= 0] *= self.alpha\n",
    "        return dinput\n",
    "\n",
    "    def get_params(self): return []\n",
    "    def get_grads(self): return []\n",
    "    def zero_grads(self): pass\n",
    "\n",
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        self.output = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.output = np.tanh(x)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout * (1 - self.output**2)\n",
    "\n",
    "    def get_params(self): return []\n",
    "    def get_grads(self): return []\n",
    "    def zero_grads(self): pass\n",
    "\n",
    "\n",
    "class BinaryCrossEntropyLoss:\n",
    "    def __init__(self, epsilon=1e-12):\n",
    "        self.epsilon = epsilon\n",
    "        self.y_pred = None\n",
    "        self.y_true = None\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.y_pred = np.clip(y_pred, self.epsilon, 1. - self.epsilon)\n",
    "        self.y_true = y_true\n",
    "        loss = - (self.y_true * np.log(self.y_pred) + \\\n",
    "                  (1 - self.y_true) * np.log(1 - self.y_pred))\n",
    "        return np.mean(loss)\n",
    "\n",
    "    def backward(self, y_pred=None, y_true=None):\n",
    "        if y_pred is None or y_true is None:\n",
    "            y_pred = self.y_pred\n",
    "            y_true = self.y_true\n",
    "        else: # Ensure clipping if new values are passed\n",
    "            y_pred = np.clip(y_pred, self.epsilon, 1. - self.epsilon)\n",
    "\n",
    "\n",
    "        batch_size = y_pred.shape[0] if len(y_pred.shape) > 0 else 1\n",
    "        grad = - (y_true / y_pred - (1 - y_true) / (1 - y_pred))\n",
    "        if batch_size > 0 : grad /= batch_size # Normalize by batch size only if batch_size > 0\n",
    "        return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12567215-9f4c-491b-9f82-7566b5d3c7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer:\n",
    "    def __init__(self, input_size, output_size, weight_initializer=he_initialize_weights):\n",
    "        self.weights = weight_initializer(input_size, output_size)\n",
    "        self.biases = np.zeros((1, output_size))\n",
    "        self.input_data = None\n",
    "        self.grad_weights = np.zeros_like(self.weights)\n",
    "        self.grad_biases = np.zeros_like(self.biases)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input_data = input_data\n",
    "        return np.dot(self.input_data, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, dout):\n",
    "        self.grad_weights = np.dot(self.input_data.T, dout)\n",
    "        self.grad_biases = np.sum(dout, axis=0, keepdims=True)\n",
    "        dinput = np.dot(dout, self.weights.T)\n",
    "        return dinput\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.weights, self.biases]\n",
    "\n",
    "    def get_grads(self):\n",
    "        return [self.grad_weights, self.grad_biases]\n",
    "\n",
    "    def zero_grads(self):\n",
    "        self.grad_weights = np.zeros_like(self.weights)\n",
    "        self.grad_biases = np.zeros_like(self.biases)\n",
    "\n",
    "class FlattenLayer:\n",
    "    def __init__(self):\n",
    "        self.original_shape = None\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.original_shape = input_data.shape\n",
    "        return input_data.reshape(self.original_shape[0], -1)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout.reshape(self.original_shape)\n",
    "\n",
    "    def get_params(self): return []\n",
    "    def get_grads(self): return []\n",
    "    def zero_grads(self): pass\n",
    "\n",
    "class ReshapeLayer:\n",
    "    def __init__(self, output_shape_tuple_excluding_batch):\n",
    "        self.output_shape_tuple = output_shape_tuple_excluding_batch\n",
    "        self.input_shape = None\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input_shape = input_data.shape\n",
    "        batch_size = self.input_shape[0]\n",
    "        return input_data.reshape(batch_size, *self.output_shape_tuple)\n",
    "\n",
    "    def backward(self, dout):\n",
    "        return dout.reshape(self.input_shape)\n",
    "\n",
    "    def get_params(self): return []\n",
    "    def get_grads(self): return []\n",
    "    def zero_grads(self): pass\n",
    "\n",
    "class Conv2DLayer:\n",
    "    def __init__(self, input_channels, num_filters, kernel_size, stride=1, padding=0,\n",
    "                 filter_initializer=he_initialize_conv_filters):\n",
    "        if isinstance(kernel_size, int):\n",
    "            self.kernel_height, self.kernel_width = kernel_size, kernel_size\n",
    "        else:\n",
    "            self.kernel_height, self.kernel_width = kernel_size\n",
    "\n",
    "        self.input_channels = input_channels\n",
    "        self.num_filters = num_filters\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        self.filters = filter_initializer(self.kernel_height, self.kernel_width,\n",
    "                                          self.input_channels, self.num_filters)\n",
    "        self.biases = np.zeros((1, 1, 1, self.num_filters))\n",
    "\n",
    "        self.input_data_shape = None # Store shape for backward pass sanity check\n",
    "        self.input_padded = None\n",
    "        self.grad_filters = np.zeros_like(self.filters)\n",
    "        self.grad_biases = np.zeros_like(self.biases)\n",
    "\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input_data_shape = input_data.shape\n",
    "        batch_size, H_in, W_in, C_in = input_data.shape\n",
    "        assert C_in == self.input_channels, f\"Input channels mismatch. Expected {self.input_channels}, got {C_in}\"\n",
    "\n",
    "        H_out = (H_in - self.kernel_height + 2 * self.padding) // self.stride + 1\n",
    "        W_out = (W_in - self.kernel_width + 2 * self.padding) // self.stride + 1\n",
    "        output = np.zeros((batch_size, H_out, W_out, self.num_filters))\n",
    "\n",
    "        if self.padding > 0:\n",
    "            self.input_padded = np.pad(input_data,\n",
    "                                       ((0, 0), (self.padding, self.padding),\n",
    "                                        (self.padding, self.padding), (0, 0)),\n",
    "                                       mode='constant', constant_values=0)\n",
    "        else:\n",
    "            self.input_padded = input_data\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for f_idx in range(self.num_filters):\n",
    "                for h_out in range(H_out):\n",
    "                    for w_out in range(W_out):\n",
    "                        h_start = h_out * self.stride\n",
    "                        h_end = h_start + self.kernel_height\n",
    "                        w_start = w_out * self.stride\n",
    "                        w_end = w_start + self.kernel_width\n",
    "                        receptive_field = self.input_padded[i, h_start:h_end, w_start:w_end, :]\n",
    "                        conv_sum = np.sum(receptive_field * self.filters[:, :, :, f_idx])\n",
    "                        output[i, h_out, w_out, f_idx] = conv_sum + self.biases[0, 0, 0, f_idx]\n",
    "        return output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        batch_size, H_out_dout, W_out_dout, num_filters_dout = dout.shape\n",
    "        batch_size_in, H_in, W_in, C_in = self.input_data_shape\n",
    "\n",
    "        assert num_filters_dout == self.num_filters\n",
    "\n",
    "        dinput_padded = np.zeros_like(self.input_padded)\n",
    "        self.grad_filters.fill(0) # Ensure grads are zeroed\n",
    "        self.grad_biases.fill(0)  # Ensure grads are zeroed\n",
    "\n",
    "        self.grad_biases = np.sum(dout, axis=(0, 1, 2), keepdims=True).reshape(self.biases.shape)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for f_idx in range(self.num_filters):\n",
    "                for h_out in range(H_out_dout):\n",
    "                    for w_out in range(W_out_dout):\n",
    "                        h_start = h_out * self.stride\n",
    "                        h_end = h_start + self.kernel_height\n",
    "                        w_start = w_out * self.stride\n",
    "                        w_end = w_start + self.kernel_width\n",
    "                        receptive_field = self.input_padded[i, h_start:h_end, w_start:w_end, :]\n",
    "                        grad_slice_dout = dout[i, h_out, w_out, f_idx]\n",
    "                        self.grad_filters[:, :, :, f_idx] += receptive_field * grad_slice_dout\n",
    "                        dinput_padded[i, h_start:h_end, w_start:w_end, :] += \\\n",
    "                            self.filters[:, :, :, f_idx] * grad_slice_dout\n",
    "\n",
    "        if self.padding > 0:\n",
    "            dinput = dinput_padded[:, self.padding:-self.padding, self.padding:-self.padding, :]\n",
    "        else:\n",
    "            dinput = dinput_padded\n",
    "        \n",
    "        #dinput matches original input_data's spatial dimensions\n",
    "        if dinput.shape[1] > H_in: dinput = dinput[:, :H_in, :, :]\n",
    "        if dinput.shape[2] > W_in: dinput = dinput[:, :, :W_in, :]\n",
    "        \n",
    "        return dinput\n",
    "\n",
    "    def get_params(self): return [self.filters, self.biases]\n",
    "    def get_grads(self): return [self.grad_filters, self.grad_biases]\n",
    "    def zero_grads(self):\n",
    "        self.grad_filters.fill(0)\n",
    "        self.grad_biases.fill(0)\n",
    "\n",
    "class MaxPooling2DLayer:\n",
    "    def __init__(self, pool_size, stride=None):\n",
    "        if isinstance(pool_size, int):\n",
    "            self.pool_height, self.pool_width = pool_size, pool_size\n",
    "        else:\n",
    "            self.pool_height, self.pool_width = pool_size\n",
    "        self.stride = stride if stride is not None else self.pool_height\n",
    "        self.input_data_shape = None\n",
    "        self.max_indices = None\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        self.input_data_shape = input_data.shape\n",
    "        batch_size, H_in, W_in, C = input_data.shape\n",
    "        H_out = (H_in - self.pool_height) // self.stride + 1\n",
    "        W_out = (W_in - self.pool_width) // self.stride + 1\n",
    "        output = np.zeros((batch_size, H_out, W_out, C))\n",
    "        self.max_indices = np.zeros((batch_size, H_out, W_out, C, 2), dtype=int)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            for c_idx in range(C):\n",
    "                for h_out in range(H_out):\n",
    "                    for w_out in range(W_out):\n",
    "                        h_start = h_out * self.stride\n",
    "                        h_end = h_start + self.pool_height\n",
    "                        w_start = w_out * self.stride\n",
    "                        w_end = w_start + self.pool_width\n",
    "                        input_patch = input_data[i, h_start:h_end, w_start:w_end, c_idx]\n",
    "                        max_val = np.max(input_patch)\n",
    "                        output[i, h_out, w_out, c_idx] = max_val\n",
    "                        idx_in_patch = np.unravel_index(np.argmax(input_patch), input_patch.shape)\n",
    "                        self.max_indices[i, h_out, w_out, c_idx, 0] = h_start + idx_in_patch[0]\n",
    "                        self.max_indices[i, h_out, w_out, c_idx, 1] = w_start + idx_in_patch[1]\n",
    "        return output\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dinput = np.zeros(self.input_data_shape)\n",
    "        batch_size_dout, H_out, W_out, C_dout = dout.shape\n",
    "        for i in range(batch_size_dout):\n",
    "            for c_idx in range(C_dout):\n",
    "                for h_out in range(H_out):\n",
    "                    for w_out in range(W_out):\n",
    "                        grad_val = dout[i, h_out, w_out, c_idx]\n",
    "                        max_r_idx = self.max_indices[i, h_out, w_out, c_idx, 0]\n",
    "                        max_c_idx = self.max_indices[i, h_out, w_out, c_idx, 1]\n",
    "                        dinput[i, max_r_idx, max_c_idx, c_idx] += grad_val\n",
    "        return dinput\n",
    "\n",
    "    def get_params(self): return []\n",
    "    def get_grads(self): return []\n",
    "    def zero_grads(self): pass\n",
    "\n",
    "\n",
    "class SequentialNetwork:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "        self.trainable_layers = [layer for layer in layers if hasattr(layer, 'get_params') and layer.get_params()]\n",
    "\n",
    "    def forward(self, x, training=True):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, dout):\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "\n",
    "    def get_params_and_grads(self):\n",
    "        params_grads = []\n",
    "        for layer in self.trainable_layers:\n",
    "            params = layer.get_params()\n",
    "            grads = layer.get_grads()\n",
    "            for p, g in zip(params, grads):\n",
    "                params_grads.append((p, g))\n",
    "        return params_grads\n",
    "\n",
    "    def zero_all_grads(self):\n",
    "        for layer in self.layers: # Zero grads for all layers that might have them\n",
    "             if hasattr(layer, 'zero_grads'):\n",
    "                layer.zero_grads()\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, network, learning_rate=0.001):\n",
    "        self.network = network\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def step(self):\n",
    "        for param, grad in self.network.get_params_and_grads():\n",
    "            if param is not None and grad is not None:\n",
    "                param -= self.learning_rate * grad\n",
    "            # else:\n",
    "            #     print(f\"Warning: param ({type(param)}) or grad ({type(grad)}) is None during SGD step.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536d266-8172-4512-bd83-58f52e27a015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting GAN training for 5 epochs, batch size 64, on 60000 images.\n",
      "\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "IMG_WIDTH = 28\n",
    "IMG_HEIGHT = 28\n",
    "CHANNELS = 1\n",
    "LATENT_DIM = 100\n",
    "\n",
    "# Generator---\n",
    "G_layers = [\n",
    "    DenseLayer(LATENT_DIM, 256, weight_initializer=xavier_initialize_weights),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    DenseLayer(256, 512, weight_initializer=xavier_initialize_weights),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    DenseLayer(512, 1024, weight_initializer=xavier_initialize_weights),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    DenseLayer(1024, IMG_HEIGHT * IMG_WIDTH * CHANNELS, weight_initializer=xavier_initialize_weights),\n",
    "    Sigmoid(),\n",
    "    ReshapeLayer((IMG_HEIGHT, IMG_WIDTH, CHANNELS))\n",
    "]\n",
    "generator = SequentialNetwork(G_layers)\n",
    "\n",
    "#Discriminator\n",
    "D_layers = [\n",
    "    Conv2DLayer(input_channels=CHANNELS, num_filters=32, kernel_size=5, stride=1, padding=2), # (28,28,1) -> (28,28,32)\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    MaxPooling2DLayer(pool_size=2, stride=2), # (28,28,32) -> (14,14,32)\n",
    "    Conv2DLayer(input_channels=32, num_filters=64, kernel_size=5, stride=1, padding=2), # (14,14,32) -> (14,14,64)\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    MaxPooling2DLayer(pool_size=2, stride=2), # (14,14,64) -> (7,7,64)\n",
    "    FlattenLayer(),\n",
    "    DenseLayer(7*7*64, 512, weight_initializer=he_initialize_weights),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    DenseLayer(512, 1, weight_initializer=xavier_initialize_weights),\n",
    "    Sigmoid()\n",
    "]\n",
    "discriminator = SequentialNetwork(D_layers)\n",
    "\n",
    "# --- Loss and Optimizers ---\n",
    "bce_loss = BinaryCrossEntropyLoss()\n",
    "lr_g = 0.001 # Adjusted learning rate\n",
    "lr_d = 0.001 # Adjusted learning rate\n",
    "optimizer_G = SGD(generator, learning_rate=lr_g)\n",
    "optimizer_D = SGD(discriminator, learning_rate=lr_d)\n",
    "\n",
    "#Training Parameter\n",
    "epochs = 5 # Increased epochs slightly, still low for quick test\n",
    "batch_size = 64 # Can adjust based on memory/speed\n",
    "sample_interval = 1\n",
    "real_label_val = 1.0\n",
    "fake_label_val = 0.0\n",
    "#faster training\n",
    "# train_images_subset = train_images[:1024]\n",
    "# num_batches = train_images_subset.shape[0] // batch_size\n",
    "# current_train_images = train_images_subset\n",
    "current_train_images = train_images # using full dataset\n",
    "num_batches = current_train_images.shape[0] // batch_size\n",
    "\n",
    "\n",
    "print(f\"Starting GAN training for {epochs} epochs, batch size {batch_size}, on {current_train_images.shape[0]} images.\")\n",
    "os.makedirs(\"gan_images_scratch\", exist_ok=True)\n",
    "\n",
    "def save_generated_images(epoch, generator_model, examples=16, dim=(4,4), figsize=(6,6)):\n",
    "    noise = np.random.randn(examples, LATENT_DIM)\n",
    "    generated_images = generator_model.forward(noise, training=False)\n",
    "    generated_images = generated_images.reshape(examples, IMG_HEIGHT, IMG_WIDTH)\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"gan_images_scratch/mnist_epoch_{epoch:04d}.png\")\n",
    "    plt.close()\n",
    "\n",
    "#Training Loop \n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    d_losses_epoch = []\n",
    "    g_losses_epoch = []\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "     \n",
    "        #  Train Discriminator\n",
    "      \n",
    "        # Zero grads for D before any D computation\n",
    "        discriminator.zero_all_grads()\n",
    "\n",
    "        # --- Train with real images ---\n",
    "        real_imgs_batch = current_train_images[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "        current_batch_size = real_imgs_batch.shape[0] # Actual batch size, could be smaller for last batch\n",
    "        real_labels = np.full((current_batch_size, 1), real_label_val)\n",
    "\n",
    "        d_output_real = discriminator.forward(real_imgs_batch)\n",
    "        d_loss_real_val = bce_loss.forward(d_output_real, real_labels)\n",
    "        d_grad_out_real = bce_loss.backward(d_output_real, real_labels)\n",
    "        discriminator.backward(d_grad_out_real)\n",
    "        optimizer_D.step() # update D based on real images\n",
    "\n",
    "        # --- Train with fake images ---\n",
    "        discriminator.zero_all_grads() # Zero grads again before fake pass for D\n",
    "        noise = np.random.randn(current_batch_size, LATENT_DIM)\n",
    "        # Detach G: G's forward pass output is used as input, no gradient flows back to G here.\n",
    "        # .copy() can ensure detachment if there were any concerns about objects being modified by reference later.\n",
    "        fake_imgs_batch_d_train = generator.forward(noise, training=False).copy()\n",
    "\n",
    "        fake_labels = np.full((current_batch_size, 1), fake_label_val)\n",
    "        d_output_fake = discriminator.forward(fake_imgs_batch_d_train)\n",
    "        d_loss_fake_val = bce_loss.forward(d_output_fake, fake_labels)\n",
    "        d_grad_out_fake = bce_loss.backward(d_output_fake, fake_labels)\n",
    "        discriminator.backward(d_grad_out_fake)\n",
    "        optimizer_D.step() # Update D based on fake images\n",
    "\n",
    "        d_total_loss_batch = (d_loss_real_val + d_loss_fake_val) / 2.0\n",
    "        d_losses_epoch.append(d_total_loss_batch)\n",
    "\n",
    "       \n",
    "        #  train Generator\n",
    "        generator.zero_all_grads() # zero G's grads\n",
    "        # discriminator's weights are \"frozen\" because optimizer_G only affects G's parameters.\n",
    "\n",
    "        noise_g_train = np.random.randn(current_batch_size, LATENT_DIM)\n",
    "        fake_images_for_g = generator.forward(noise_g_train)\n",
    "        # D's forward pass with G's output. D is not in training mode here w.r.t its own updates.\n",
    "        d_output_for_g = discriminator.forward(fake_images_for_g)\n",
    "\n",
    "        g_loss_val = bce_loss.forward(d_output_for_g, real_labels) # G wants D to predict these as real\n",
    "        g_losses_epoch.append(g_loss_val)\n",
    "\n",
    "        grad_loss_wrt_d_output = bce_loss.backward(d_output_for_g, real_labels)\n",
    "        # rads from D up to its input (G's output).\n",
    "        # D's internal grads are computed, not used by optimizer_D here\n",
    "        grad_d_wrt_g_output = discriminator.backward(grad_loss_wrt_d_output)\n",
    "        generator.backward(grad_d_wrt_g_output) # backprop through G\n",
    "\n",
    "        optimizer_G.step() \n",
    "\n",
    "        if (batch_idx + 1) % (num_batches // 10 if num_batches > 10 else 1) == 0: # Print progress a few times per epoch\n",
    "            print(f\"  Batch {batch_idx+1}/{num_batches} -- D Loss: {d_total_loss_batch:.4f}, G Loss: {g_loss_val:.4f}\")\n",
    "\n",
    "    avg_d_loss = np.mean(d_losses_epoch) if d_losses_epoch else 0\n",
    "    avg_g_loss = np.mean(g_losses_epoch) if g_losses_epoch else 0\n",
    "    print(f\"Epoch {epoch+1} finished. Avg D Loss: {avg_d_loss:.4f}, Avg G Loss: {avg_g_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % sample_interval == 0:\n",
    "        save_generated_images(epoch + 1, generator)\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ab0d11-cdcc-402a-980d-37524da4595f",
   "metadata": {},
   "source": [
    "# Discriminator’s CNN Architecture\n",
    "\n",
    "The Discriminator in your GAN is a Convolutional Neural Network (CNN) designed to classify images as real or fake, featuring the following architecture: a Conv2DLayer that transforms the input from (28, 28, 1) to (28, 28, 32) using 32 filters with a 5x5 kernel, stride 1, and padding 2, followed by a LeakyReLU activation; a MaxPooling2DLayer that reduces the size to (14, 14, 32) with a 2x2 pool and stride 2; another Conv2DLayer that maps (14, 14, 32) to (14, 14, 64) with 64 filters, a 5x5 kernel, stride 1, and padding 2, followed by another LeakyReLU; a second MaxPooling2DLayer that downsamples to (7, 7, 64) with a 2x2 pool and stride 2; a FlattenLayer that reshapes (7, 7, 64) to (3136,); a DenseLayer reducing (3136, 512) with LeakyReLU activation; a final DenseLayer from (512, 1) with a Sigmoid activation, producing a single output value between 0 and 1 to indicate if the input image is fake (0) or real (1).\n",
    "\n",
    "## How Backpropagation Works in the Discriminator\n",
    "\n",
    "Backpropagation computes gradients of the loss with respect to weights and biases by propagating errors backward. The loss, defined by BinaryCrossEntropyLoss as $( L = -\\frac{1}{N} \\sum [y \\log(D(x)) + (1-y) \\log(1-D(x))])$, yields an initial gradient $( \\frac{\\partial L}{\\partial D(x)} = -\\frac{1}{N} \\left( \\frac{y}{D(x)} - \\frac{1-y}{1-D(x)} \\right))$, computed in `BinaryCrossEntropyLoss.backward()` and passed to the Sigmoid layer. The Sigmoid layer scales the gradient by $( \\sigma(z)(1-\\sigma(z)))$, while each DenseLayer computes $( \\frac{\\partial L}{\\partial W} = \\frac{\\partial L}{\\partial z} \\cdot x^T )$, $( \\frac{\\partial L}{\\partial b} = \\frac{\\partial L}{\\partial z} )$, and $( \\frac{\\partial L}{\\partial x} = \\frac{\\partial L}{\\partial z} \\cdot W^T )$, passing $( \\frac{\\partial L}{\\partial x} )$ to LeakyReLU, which scales by 1 (if $( x > 0 ))$ or 0.2 (if $( x \\leq 0 ))$. \n",
    "\n",
    "The FlattenLayer reshapes the gradient from (3136,) to (7, 7, 64) for the MaxPooling2DLayer. In the MaxPooling2DLayer, the forward pass stores max indices per 2x2 patch, and the backward pass routes the incoming gradient (ex: (7, 7, 64)) to the max position in the input patch (ex: (14, 14, 64)), setting others to 0, facing challenges like non-differentiability at ties (approximated by choosing the first max), gradient sparsity slowing learning for non-max neurons, and memory overhead from storing indices. \n",
    "\n",
    "The LeakyReLU then scales the gradient by 1 or 0.2, passing it to the Conv2DLayer, where the forward pass computes output as $( \\sum_{h,w,c} input[i, h_{start}:h_{end}, w_{start}:w_{end}, c] \\cdot filters[h, w, c, f_{idx}] + biases[f_{idx}] )$. The backward pass calculates $( \\frac{\\partial L}{\\partial filters} )$ by multiplying the gradient with the input patch, $( \\frac{\\partial L}{\\partial biases} )$ by summing gradients, and $( \\frac{\\partial L}{\\partial input} )$ by convolving the gradient with filters, adjusting for padding, with challenges including padding handling (slicing to match input dimensions), numerical stability (mitigated by normalizing inputs to [0, 1]), and computational complexity from iterating over positions and channels. \n",
    "\n",
    "This process repeats for earlier layers, stopping at the input image. Visualizing the first block (Conv2DLayer → LeakyReLU → MaxPooling2DLayer) with an input (1, 28, 28, 1), the Conv2DLayer outputs (1, 28, 28, 32) via 5x5 patch sums, LeakyReLU applies $( f(x) = x $) or $( 0.2x $), and MaxPooling2DLayer outputs (1, 14, 14, 32) by taking maxima; in the backward pass, a gradient (ex: 0.5 at (0, 0, 0)) is routed by MaxPooling2DLayer to the max position (ex: (1, 1)), scaled by LeakyReLU, and the Conv2DLayer updates filters, biases, and input gradient accordingly."
   ]
  },
  {
   "cell_type": "raw",
   "id": "70b30bf7-659b-4c0b-9ec8-552b23a7b0d0",
   "metadata": {},
   "source": [
    "Loss → ... → MaxPooling2DLayer → LeakyReLU → Conv2DLayer → Input\n",
    "   ↑           ↑              ↑           ↑           ↑\n",
    "dout       (14, 14, 32)    (28, 28, 32)  (28, 28, 32)  (28, 28, 1)\n",
    "   |           |              |           |           |\n",
    "Routes to max  |            Scales by    Updates filters,\n",
    "position      |            1 or 0.2     biases, input grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2474630d-b9d4-4848-8b50-adb17b9aaf03",
   "metadata": {},
   "source": [
    "## Challenges during training for backward pass for non linear training:\n",
    "\n",
    "**Max Pooling:**\n",
    "\n",
    "Non-Differentiability: As mentioned, max pooling is non-differentiable at points of ambiguity (e.g., ties). The code assumes the first maximum encountered is used, which is a practical approximation.\n",
    "Gradient Sparsity: Only the maximum position gets a gradient, which can lead to underutilization of some neurons. This is a known limitation of max pooling compared to average pooling.\n",
    "Memory Usage: Storing self.max_indices increases memory overhead, especially for large inputs or many channels.\n",
    "\n",
    "**LeakyReLU:**\n",
    "\n",
    "Vanishing Gradients (Partially Mitigated): LeakyReLU helps avoid vanishing gradients (unlike ReLU, which sets gradients to 0 for negative inputs) by allowing a small gradient (a=0.2)for negative values. However, the small gradient can still slow learning for neurons with consistently negative inputs.\n",
    "Numerical Stability: The code clips values in Sigmoid (-700, 700), but LeakyReLU doesn’t need such clipping since it’s linear in both regions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35af4d8a-3295-4dae-b4d8-66729fa107eb",
   "metadata": {},
   "source": [
    "## Image generation quality (visual comparison of generated anime faces):\n",
    "\n",
    "Without Pytorch : Generated images are likely to have lower resolution (28x28) and may exhibit blocky or blurry features due to the aggressive downsampling and limited filter sizes. The lack of batch normalization or advanced regularization, could lead to mode collapse or inconsistent face generation.\n",
    "\n",
    "With Pytorch: The plot generated in lab7 shows that the discriminator effectively distinguishes real (higher scores) from fake (lower scores) over epochs, suggesting stable training and potentially higher-quality outputs. Larger resolutions (e.g., 64x64) and advanced features like batch normalization likely produce sharper, more detailed anime faces with better color and texture fidelity compared to the custom 28x28 grayscale images.\n",
    "\n",
    "## Training stability and convergence:\n",
    "\n",
    "Without Pytorch: This implementation uses manually defined backward methods for layers (ex Conv2DLayer, MaxPooling2DLayer), with gradients computed via explicit rules (ex: routing to max positions in pooling, convolution with filters). The code lacks evidence of advanced stabilization techniques like label smoothing, gradient penalty, or Adam optimizer with tuned hyperparameters, which are critical for GAN stability.\n",
    "Convergence: Without these features, the training may suffer from mode collapse or oscillatory behavior, where the Generator produces limited variety or the Discriminator overpowers the Generator. The absence of a score plot in bonus2.ipynb makes it hard to assess convergence, but the manual gradient flow could introduce numerical instability.\n",
    "\n",
    "With Pytorch: The presence of a real vs. fake score plot (generated via plt.plot(real_scores, fake_scores)) suggests the use of an optimizer and loss function (binary cross-entropy), with the Discriminator and Generator trained alternately. PyTorch’s automatic differentiation and GPU acceleration (noted in metadata) enable stable gradient updates. The upward trend in real scores and downward trend in fake scores indicate balanced training and convergence toward distinguishing real anime faces.\n",
    "Convergence: The plot implies the GAN converges well, with the Discriminator improving over epochs, likely aided by batch normalization and a robust optimizer, reducing the risk of mode collapse compared to the custom implementation.\n",
    "\n",
    "\n",
    "## The intricacies of training stability in adversarial models like GANs:\n",
    "\n",
    "without Pytorch: The custom implementation relies on NumPy-like operations for forward and backward passes, executed on the CPU unless manually optimized. The lack of vectorization or GPU support suggests slower training, especially with two convolution layers and dense layers for each batch. Processing 28x28 images with 32 and 64 filters is computationally lightweight but inefficient without optimization.\n",
    "Memory usage is moderate due to the small image size and layer counts, but storing max indices in MaxPooling2DLayer (ex: batch_size × 7 × 7 × 64 × 2) adds overhead. No batch normalization or large batch sizes are evident, keeping resource demands low but limiting scalability.\n",
    "PyTorch-based GAN Implementation:\n",
    "\n",
    "With Pytorch:The use of PyTorch with GPU acceleration significantly speeds up training by leveraging CUDA for matrix operations across Conv2d and ConvTranspose2d layers. The plot generation over epochs suggests efficient batch processing, likely with larger batch sizes and higher-resolution images (ex: 64x64), increasing computational demand but optimized by PyTorch’s framework.\n",
    "Higher memory usage is expected due to larger images, deeper networks, and batch normalization, but GPU offloading mitigates this. The Colab environment with GPU support ensures efficient resource utilization compared to the CPU-bound custom implementation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
